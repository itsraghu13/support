def get_activity_output_data(activity_runs, pipeline_runId, pipelinename):
    """
    This function takes in a list of activity runs, a pipeline run ID, and a pipeline name.
    It filters the activity runs to only keep those with activityType "Copy".
    For each "Copy" activity, it extracts the output data ("rowsRead" or "dataRead") and creates a dictionary
    containing relevant information such as run ID, pipeline name, rows read/written, and activity name.
    The dictionaries are appended to a result list.
    At the end, the function returns the result list.
    """
    result = []
    for activity in activity_runs:
        if activity["activityType"] == "Copy":
            output = activity["output"]
            if "rowsRead" in output:
                rowsRead_data = {
                    "RunID": pipeline_runId,
                    "PipelineName": pipelinename,
                    "RowsRead": output["rowsRead"],
                    "RowsWritten": output["rowsCopied"],
                    "ActivityName": activity["activityName"]
                }
                result.append(rowsRead_data)
            elif "dataRead" in output:
                dataRead_data = {
                    "RunID": pipeline_runId,
                    "PipelineName": pipelinename,
                    "RowsRead": output["dataRead"],
                    "RowsWritten": output["dataWritten"],
                    "ActivityName": activity["activityName"]
                }
                result.append(dataRead_data)

    return result






import requests

def get_pipeline_runs(adf_url: str, headers: dict) -> list:
    """
    Sends a POST request to the Azure Data Factory API to retrieve pipeline runs.
    
    Args:
    adf_url (str): The Azure Data Factory URL to send the request to.
    headers (dict): The headers to include in the request.

    Returns:
    A list of pipeline runs retrieved from the API.
    """
    try:
        response = requests.post(adf_url, headers=headers)
        response.raise_for_status()
        return response.json()['value']
    except requests.exceptions.HTTPError as errh:
        print("HTTP error:", errh)
    except requests.exceptions.ConnectionError as errc:
        print("Connection error:", errc)
    except requests.exceptions.Timeout as errt:
        print("Timeout error:", errt)
    except requests.exceptions.RequestException as err:
        print("Oops! Something went wrong:", err)

# Define the ADF URL and headers
adf_url = 'https://<your-adf-name>.azuredatafactory.net/api/v1/PipelineRuns/QueryByFactory'
headers = {
    'Authorization': 'Bearer <your-token>',
    'Content-Type': 'application/json'
}

# Get pipeline runs
pipeline_runs = get_pipeline_runs(adf_url, headers)















import requests

def get_pipeline_runs(adf_url: str, headers: dict) -> list:
    """
    Sends a POST request to the Azure Data Factory API to retrieve pipeline runs.
    
    Args:
    adf_url (str): The Azure Data Factory URL to send the request to.
    headers (dict): The headers to include in the request.

    Returns:
    A list of pipeline runs retrieved from the API.
    """
    response = requests.post(adf_url, headers=headers)
    if response.status_code != 200:
        print(f"ERROR: Request failed with status {response.status_code}")
        return []
    return response.json()['value']

# Define the ADF URL and headers
adf_url = 'https://<your-adf-name>.azuredatafactory.net/api/v1/PipelineRuns/QueryByFactory'
headers = {
    'Authorization': 'Bearer <your-token>',
    'Content-Type': 'application/json'
}

# Get pipeline runs
pipeline_runs = get_pipeline_runs(adf_url, headers)











def get_parent_id_recursive(parameters_data, pipeline_runId):
    parent_id = None
    current_id = None
    
    for key, value in parameters_data.items():
        if key == "invokedBy":
            if value['invokedByType'] != "Manual":
                current_id = value['pipelineRunId']
                parent_id, current_id = get_parent_id_recursive(parameters_data, current_id)
            else:
                parent_id = pipeline_runId
                
    return parent_id, current_id




for item in data:
    pipeline_runs = get_pipeline_runs(adf_url, headers)
    result = get_activity_output_data(pipeline_runs, item['run_id'], item['pipelineName'])
    parent_id, current_id = get_parent_id_recursive(result['parameters'], item['run_id'])
    print(parent_id)
















# Define the URL to fetch pipeline runs
adf_url = "https://management.azure.com/subscriptions/{}/resourceGroups/{}/providers/Microsoft.Datafactory/factories/{}/pipelineruns".format(
    subscription_id, resource_GroupName, factory_name)

# Define the headers for authorization
headers = {
    "Authorization": "Bearer {}".format(access_token)
}

# Loop through the data list and process each item
for item in data:
    
    # Get the pipeline runs
    pipeline_runs = get_pipeline_runs(adf_url, headers, item['run_id'], last_updated_after, last_updated_before, item['pipelineName'])
    
    # Get the result of the activity output data
    result = get_activity_output_data(pipeline_runs, item['run_id'], item['pipelineName'])
    
    # Get the parent run id recursively
    parent_runid = get_parent_id_recursive(item['run_id'], pipeline_runs)
    
    # Print the parent run id
    print(parent_runid)
    
    # If there is a parent run id, define the schema with additional column
    if parent_runid:
        schema = StructType([
            StructField("ActivityName", StringType(), True),
            StructField("PipelineName", StringType(), True),
            StructField("RowsRead", LongType(), True),
            StructField("RowsWritten", LongType(), True),
            StructField("RunID", StringType(), True),
            StructField("Parent_RunId", StringType(), True)
        ])
    else:
        schema = StructType([
            StructField("ActivityName", StringType(), True),
            StructField("PipelineName", StringType(), True),
            StructField("RowsRead", LongType(), True),
            StructField("RowsWritten", LongType(), True),
            StructField("RunID", StringType(), True)
        ])
    
    # Create a Spark dataframe from the result and schema
    if result:
        df = spark.createDataFrame(result, schema=schema)
    else:
        df = spark.createDataFrame([(None, item['pipelineName'], None, None, item['run_id'])], schema=schema)
    
    # Add parent_runid column to the dataframe
    if parent_runid:
        df = df.withColumn("Parent_RunId", lit(parent_runid[0]))
    
    # Write the dataframe to delta table
    df.write.format("delta").mode("append").option("overwriteSchema", "true").saveAsTable('structured.t_child_rgv')


















def get_parent_id_recursive(pipeline_runId):
    response = requests.get(adf_url, headers=headers)
    parameters_data = json.loads(response.text)

    parent_id = None
    current_id = None

    # Loop through the items in the parameters_data dictionary
    for key, value in parameters_data.items():
        if key == "invokedBy":
            if value['invokedByType'] != "Manual":
                current_id = value['pipelineRunId']
                break

    # If a current_id was found, call the function recursively with that id and update the parent_id
    if current_id:
        parent_id, _ = get_parent_id_recursive(current_id)
    else:
        parent_id = pipeline_runId
    
    return parent_id, current_id
    
    
    
    
    
    
    
    
    
    
    def get_activity_output_data(activity_runs, pipeline_runId, pipelinename):
    """
    This function takes in a list of activity runs, a pipeline run ID, and a pipeline name.
    It filters the activity runs to only keep those with activityType "Copy".
    For each "Copy" activity, it extracts the output data ("rowsRead" or "dataRead") and creates a dictionary
    containing relevant information such as run ID, pipeline name, rows read/written, and activity name.
    The dictionaries are appended to a result list.
    At the end, the function returns the result list.
    """
    result = []
    for activity in activity_runs:
        if "activityType" in activity and activity["activityType"] == "Copy":
            output = activity["output"]
            if "rowsRead" in output:
                rowsRead_data = {
                    "RunID": pipeline_runId,
                    "PipelineName": pipelinename,
                    "RowsRead": output["rowsRead"],
                    "RowsWritten": output["rowsCopied"],
                    "ActivityName": activity["activityName"]
                }
                result.append(rowsRead_data)
            elif "dataRead" in output:
                dataRead_data = {
                    "RunID": pipeline_runId,
                    "PipelineName": pipelinename,
                    "RowsRead": output["dataRead"],
                    "RowsWritten": output["dataWritten"],
                    "ActivityName": activity["activityName"]
                }
                result.append(dataRead_data)

    return result









def get_parent_id_recursive(adf_url, headers, pipeline_runId):
    response = requests.get(adf_url, headers=headers)
    parameters_data = json.loads(response.text)

    parent_id = None
    current_id = None

    # Loop through the items in the parameters_data dictionary
    for key, value in parameters_data.items():
        if key == "invokedBy":
            if value['invokedByType'] != "Manual":
                current_id = value['pipelineRunId']
                break

    # If a current_id was found, call the function recursively with that id and update the parent_id
    if current_id:
        parent_id, _ = get_parent_id_recursive(adf_url, headers, current_id)
    else:
        parent_id = pipeline_runId
    
    return parent_id

