SELECT meta_pipelines.pipeline_name, meta_pipelines.status, AVG(meta_copyactivity.rows_read) AS avg_rows_read, AVG(meta_copyactivity.data_read) AS avg_data_read, AVG(meta_copyactivity.rows_written) AS avg_rows_written, AVG(meta_copyactivity.data_written) AS avg_data_written FROM meta_pipelines INNER JOIN meta_copyactivity ON meta_pipelines.run_id = meta_copyactivity.parent_runid GROUP BY meta_pipelines.pipeline_name, meta_pipelines.status


SELECT
    mp.run_id AS pipeline_run_id,
    mp.start_time AS pipeline_start_time,
    mp.end_time AS pipeline_end_time,
    mc.activity_runid AS activity_run_id,
    mc.activity_name AS activity_name,
    dl.table_name AS loaded_table,
    SUM(dl.row_count) AS total_row_count_loaded
FROM
    meta_pipelines mp
JOIN
    meta_copyactivity mc ON mp.run_id = mc.parent_runid
LEFT JOIN
    dataload dl ON mc.activity_runid = dl.parent_runid
GROUP BY
    mp.run_id,
    mp.start_time,
    mp.end_time,
    mc.activity_runid,
    mc.activity_name,
    dl.table_name
ORDER BY
    pipeline_run_id,
    activity_run_id,
    loaded_table;















from unidecode import unidecode

def remove_diacritics_and_replace(input_str):
    return unidecode(input_str)

input_string = "Joaé Ëx Âpple ñice Þorn"
modified_string = remove_diacritics_and_replace(input_string)
print(modified_string)














import pyspark.sql.functions as F

def remove_diacritics_udf(input_str):
    return F.udf(lambda x: unidecode(x))(input_str)

schema = StructType([StructField('text', StringType(), True)])

spark_df = spark.createDataFrame(data=[['Joaé Ëxample Æpple ñicely Þorn']], schema=schema)

spark_df = spark_df.withColumn('text_no_diacritics', remove_diacritics_udf(spark_df['text']))

print(spark_df.show())














schema = StructType([StructField('text', StringType(), True)])

spark_df = spark.createDataFrame(data=[['Joaé Ëxample Æpple ñicely Þorn']], schema=schema)















import pyspark.sql.functions as F

def remove_diacritics_udf(input_str):
    return F.udf(lambda x: unidecode(x))(input_str)

spark_df = spark.createDataFrame({'text': ['Joaé Ëxample Æpple ñicely Þorn']})

spark_df = spark_df.withColumn('text_no_diacritics', remove_diacritics_udf(spark_df['text']))

print(spark_df.show())












from unidecode import unidecode

def remove_diacritics_and_replace(input_str):
    return unidecode(input_str)

input_string = "Joaé Ëxample Âpple ñicely Þorn"
modified_string = remove_diacritics_and_replace(input_string)
print(modified_string)












import unicodedata

def remove_diacritics_and_replace(input_str):
    normalized_str = unicodedata.normalize('NFD', input_str)
    output_str = ''
    
    replacement_dict = {
        unicodedata.normalize('NFD', 'À'): 'A',
        unicodedata.normalize('NFD', 'Á'): 'A',
        unicodedata.normalize('NFD', 'Â'): 'A',
        unicodedata.normalize('NFD', 'Ã'): 'A',
        unicodedata.normalize('NFD', 'Ä'): 'A',
        unicodedata.normalize('NFD', 'Å'): 'A',
        unicodedata.normalize('NFD', 'à'): 'a',
        unicodedata.normalize('NFD', 'á'): 'a',
        unicodedata.normalize('NFD', 'â'): 'a',
        unicodedata.normalize('NFD', 'ã'): 'a',
        unicodedata.normalize('NFD', 'ä'): 'a',
        unicodedata.normalize('NFD', 'å'): 'a',
        unicodedata.normalize('NFD', 'È'): 'E',
        unicodedata.normalize('NFD', 'É'): 'E',
        # ... and so on for other characters in the dictionary
    }
    
    for c in normalized_str:
        output_str += replacement_dict.get(c, c)
    
    return output_str

input_string = "Joaé Ëxample Âpple ñicely Þorn"
modified_string = remove_diacritics_and_replace(input_string)
print(modified_string)






















def remove_diacritics_and_replace(input_str):
    normalized_str = unicodedata.normalize('NFD', input_str)
    output_str = ''
    
    replacement_dict = {
        'À': 'A', 'Á': 'A', 'Â': 'A', 'Ã': 'A', 'Ä': 'A', 'Å': 'A',
        'à': 'a', 'á': 'a', 'â': 'a', 'ã': 'a', 'ä': 'a', 'å': 'a',
        'È': 'E', 'É': 'E', 'Ê': 'E', 'Ë': 'E',
        'è': 'e', 'é': 'e', 'ê': 'e', 'ë': 'e',
        'Ì': 'I', 'Í': 'I', 'Î': 'I', 'Ï': 'I',
        'ì': 'i', 'í': 'i', 'î': 'i', 'ï': 'i',
        'Ò': 'O', 'Ó': 'O', 'Ô': 'O', 'Õ': 'O', 'Ö': 'O', 'Ø': 'O',
        'ò': 'o', 'ó': 'o', 'ô': 'o', 'õ': 'o', 'ö': 'o', 'ø': 'o',
        'Ù': 'U', 'Ú': 'U', 'Û': 'U', 'Ü': 'U',
        'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u',
        'Ý': 'Y', 'ý': 'y', 'ÿ': 'y',
        'Ç': 'C', 'ç': 'c',
        'Ñ': 'N', 'ñ': 'n',
        'Æ': 'AE', 'æ': 'ae',
        'Þ': 'Th', 'þ': 'th', 'Ð': 'D', 'ð': 'd',  # Icelandic characters
        'ß': 'ss',
        'œ': 'oe', 'Œ': 'OE',
        'Ā': 'A', 'ā': 'a', 'Ă': 'A', 'ă': 'a', 'Ą': 'A', 'ą': 'a',  # Latin extended-A
        'Ć': 'C', 'ć': 'c', 'Ĉ': 'C', 'ĉ': 'c', 'Ċ': 'C', 'ċ': 'c',
    }
    
    for c in normalized_str:
        output_str += replacement_dict.get(c, c)
    
    return output_str

input_string = "Joaé Ëxample Âpple ñicely Þorn"
modified_string = remove_diacritics_and_replace(input_string)
print(modified_string)

